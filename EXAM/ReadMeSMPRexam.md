# Экзамен СМПР

[1. Задача обучения по прецедентам. Основные понятия и определения](https://github.com/Elzara20/university/blob/master/EXAM/ReadMeSMPRexam.md#1%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F-%D0%BF%D0%BE-%D0%BF%D1%80%D0%B5%D1%86%D0%B5%D0%B4%D0%B5%D0%BD%D1%82%D0%B0%D0%BC-%D0%BE%D1%81%D0%BD%D0%BE%D0%B2%D0%BD%D1%8B%D0%B5-%D0%BF%D0%BE%D0%BD%D1%8F%D1%82%D0%B8%D1%8F-%D0%B8-%D0%BE%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F)

[2. Модель алгоритмов и метод обучения. Функционал качества и функция потерь](https://github.com/Elzara20/university/blob/master/EXAM/ReadMeSMPRexam.md#2-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%BE%D0%B2-%D0%B8-%D0%BC%D0%B5%D1%82%D0%BE%D0%B4-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F-%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB-%D0%BA%D0%B0%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%B0-%D0%B8-%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F-%D0%BF%D0%BE%D1%82%D0%B5%D1%80%D1%8C)

[3. Проблема переобучения и понятие обобщающей способности. Эмпирические оценки обобщающей способности. Разновидности скользящего контроля](https://github.com/Elzara20/university/blob/master/EXAM/ReadMeSMPRexam.md#3-%D0%BF%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D0%B0-%D0%BF%D0%B5%D1%80%D0%B5%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F-%D0%B8-%D0%BF%D0%BE%D0%BD%D1%8F%D1%82%D0%B8%D0%B5-%D0%BE%D0%B1%D0%BE%D0%B1%D1%89%D0%B0%D1%8E%D1%89%D0%B5%D0%B9-%D1%81%D0%BF%D0%BE%D1%81%D0%BE%D0%B1%D0%BD%D0%BE%D1%81%D1%82%D0%B8-%D1%8D%D0%BC%D0%BF%D0%B8%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5-%D0%BE%D1%86%D0%B5%D0%BD%D0%BA%D0%B8-%D0%BE%D0%B1%D0%BE%D0%B1%D1%89%D0%B0%D1%8E%D1%89%D0%B5%D0%B9-%D1%81%D0%BF%D0%BE%D1%81%D0%BE%D0%B1%D0%BD%D0%BE%D1%81%D1%82%D0%B8-%D1%80%D0%B0%D0%B7%D0%BD%D0%BE%D0%B2%D0%B8%D0%B4%D0%BD%D0%BE%D1%81%D1%82%D0%B8-%D1%81%D0%BA%D0%BE%D0%BB%D1%8C%D0%B7%D1%8F%D1%89%D0%B5%D0%B3%D0%BE-%D0%BA%D0%BE%D0%BD%D1%82%D1%80%D0%BE%D0%BB%D1%8F)

[4-6 Метрические алгоритмы классификации](https://github.com/Elzara20/university/blob/master/EXAM/ReadMeSMPRexam.md#4-6-%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B-%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8)


[4. Метрические алгоритмы классификации: алгоритмы ближайших соседей](https://github.com/Elzara20/university/blob/master/EXAM/ReadMeSMPRexam.md#4-%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B-%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B-%D0%B1%D0%BB%D0%B8%D0%B6%D0%B0%D0%B9%D1%88%D0%B8%D1%85-%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B5%D0%B9)

[5. Метрические алгоритмы классификации: метод парзеновского окна](https://github.com/Elzara20/university/blob/master/EXAM/ReadMeSMPRexam.md#5-%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B-%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8-%D0%BC%D0%B5%D1%82%D0%BE%D0%B4-%D0%BF%D0%B0%D1%80%D0%B7%D0%B5%D0%BD%D0%BE%D0%B2%D1%81%D0%BA%D0%BE%D0%B3%D0%BE-%D0%BE%D0%BA%D0%BD%D0%B0)

[6. Метрические алгоритмы классификации: метод потенциальных функций](https://github.com/Elzara20/university/blob/master/EXAM/ReadMeSMPRexam.md#6-%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B-%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8-%D0%BC%D0%B5%D1%82%D0%BE%D0%B4-%D0%BF%D0%BE%D1%82%D0%B5%D0%BD%D1%86%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D1%85-%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%B9)

[7. Понятие отступа объекта. Эталонные объекты. Алгоритм STOLP](https://github.com/Elzara20/university/blob/master/EXAM/ReadMeSMPRexam.md#7-%D0%BF%D0%BE%D0%BD%D1%8F%D1%82%D0%B8%D0%B5-%D0%BE%D1%82%D1%81%D1%82%D1%83%D0%BF%D0%B0-%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%B0-%D1%8D%D1%82%D0%B0%D0%BB%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5-%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D1%8B-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC-stolp)





## 1.Задача обучения по прецедентам. Основные понятия и определения.
Задано множество объектов ![](https://latex.codecogs.com/gif.latex?X), множество допустимых ответов ![](https://latex.codecogs.com/gif.latex?Y), и существует целевая функция (target function) ![](https://latex.codecogs.com/gif.latex?y^*:X&space;\rightarrow&space;Y) значения которой ![](https://latex.codecogs.com/gif.latex?y_i=y^*(x_i)) известны только на конечном подмножестве объектов ![](https://latex.codecogs.com/gif.latex?x_i&space;\subset&space;X). Пары «объект–ответ» (xi, yi) называются прецедентами. Совокупность пар ![](https://latex.codecogs.com/gif.latex?X^l=(x_i,y_i)_{i=1}^l) называется обучающей выборкой (training sample).
Задача обучения по прецедентам заключается в том, чтобы восстановить функциональную зависимость между объектами и ответами, то есть построить отображение ![](https://latex.codecogs.com/gif.latex?a:X&space;\rightarrow&space;Y) удовлетворяющее следующей совокупности требований:
- отображение должно допускать эффективную компьютерную реализацию. Отображение а - называется алгоритмом.
- алгоритм а(х) должен воспроизводить на объектах выборки заданные ответы: ![](https://latex.codecogs.com/gif.latex?a(x_i)=y_i). Равенство может быть точным или приближенным, в зависимости от задачи.
- На алгоритм a(x) могут накладываться разного рода априорные ограничения, например, требования непрерывности, гладкости, монотонности, и т. д., или сочетание нескольких требований. В некоторых случаях может задаваться модель алгоритма — ***функциональный вид отображения a(x)***, определённый с точностью до параметров.
- Алгоритм ![](https://latex.codecogs.com/gif.latex?a) должен обладать обобщающей способностью (generalization ability) - достаточно точно приближать целевую функцию ![](https://latex.codecogs.com/gif.latex?y^*(x)) на всём множестве X.
#### Разновидность задач обучения по прецедентам
В зависимости от множества У задачи обучения делятся на следующие типы:

- ![](https://latex.codecogs.com/gif.latex?Y%3D%5Cleft%20%5C%7B%201%2C%5Ccdots%20%2CM%20%5Cright%20%5C%7D) 
Задача классификации (classification) на M <ins>непересекающихся</ins> классов. В некоторых приложениях классы называют образами и говорят о задаче распознавания образов (pattern recognition). 
Алгоритм задачи классификации отвечает на вопрос - к какому классу принадлежит.
Пример: определить пациент болен или нет, письмо спам или нет.
- ![](https://latex.codecogs.com/gif.latex?Y%3D%5Cleft%20%5C%7B%200%2C1%20%5Cright%20%5C%7D)
M — задача классификации на M пересекающихся классов. В простейшем случае эта задача сводится к решению M независимых задач классификации с двумя непересекающимися классами.
Алгоритм задачи классификации отвечает на вопрос - к какому классу принадлежит.
Пример: классификация роз и шиповников, характеристики (побег, листья, соцветья и тд) остаются одинаковыми для двух классов, и какие-то параметры могут совпадать ( роза и шиповник из рода Шиповников).
- Y = R — задача восстановления регрессии (regression estimation).
Пример: определить стоимость проекта по параметрам: актуальность проекта, заинтересованность инвесторами, прогноз специалистов и тд.
- Задача прогнозирования (forecasting) является частным случаем классификации или восстановления регрессии, когда X — описание прошлого поведения объекта, Y — описание некоторых характеристик его будущего поведения.
Пример: спрогназировать акции компании или курс валюты, по имеющимся прошлым показаниям.

#### Объекты и признаки

Признак (feature) f объекта x — это результат измерения некоторой характеристики объекта. Формально признаком называется отображение ![](https://latex.codecogs.com/gif.latex?f:X\rightarrow&space;D_f), где ![](https://latex.codecogs.com/gif.latex?D_f) — множество допустимых значений признака. Любое отображение из множества Х можно рассматривать как признак. В частности, любой алгоритм ![](https://latex.codecogs.com/gif.latex?a:X\rightarrow&space;Y) также можно рассматривать как признак.

В зависимости от множества допустимых значений признаки делятся на следующие типы:
- *бинарный признак*:  ![](https://latex.codecogs.com/gif.latex?D_f%3D%5Cleft%20%5C%7B%200%2C1%20%5Cright%20%5C%7D)
- *номинальный*: ![](https://latex.codecogs.com/gif.latex?D_f) - конечное множество.
- *порядковый*: ![](https://latex.codecogs.com/gif.latex?D_f) - конечное упорядоченное множество.
- *количественный* ![](https://latex.codecogs.com/gif.latex?D_f=\mathbb{R})

Значениями признаков могут быть числовые последовательности, растровые изображения, функции, графы, результаты запросов к базе данных, и тд. Если все признаки имеют одинаковый тип, то исходные данные называются **однородными**, в противном случае - **разнородными**. 

Есть набор признаков ![](https://latex.codecogs.com/gif.latex?f_1,\cdots&space;,f_n).
![](https://latex.codecogs.com/gif.latex?%5Cleft%20%28f_1%28x%29%2C%5Ccdots%20%2Cf_n%28x%29%20%5Cright%20%29) - вектор признакового описания объекта ![](https://latex.codecogs.com/gif.latex?x\in&space;X). Совокупность признаковых описаний всех объектов выборки можно записать в матрицу (матрица объектов-признаков)
>Встречаются задачи, в которых данные устроены сложнее, например, описания объектов могут иметь переменную длину. В таких случаях по имеющимся исходным данным вычисляются преобразованные данные, имеющие стандартный вид. Этот приём называется извлечением признаков (features extraction) из данных.
#### Модель алгоритмов и метод обучения
Моделью алгоритмов называется параметрическое семейство отображений ![](https://latex.codecogs.com/gif.latex?A%3D%5Cleft%20%5C%7B%20g%28x%2C%5Ctheta%29%20%7C%20%5Ctheta%20%5Cin%20%5CTheta%20%5Cright%20%5C%7D%2C%20%5C%3A%20g%3AX%5Ctimes%20%5CTheta%20%5Crightarrow%20Y), g — некоторая фиксированная функция, ![](https://latex.codecogs.com/gif.latex?\Theta) — множество допустимых значений параметра ![](https://latex.codecogs.com/gif.latex?\theta), называемое пространством параметров или пространством поиска (search space).

Линейные модели с вектором параметров ![](https://latex.codecogs.com/gif.latex?%5Ctheta%3D%5Cleft%20%28%5Ctheta_1%2C%5Ccdots%20%2C%20%5Ctheta_n%20%5Cright%20%29%5Cin%20%5CTheta%20%3D%5Cmathbb%7BR%7D%5En):

- ![](https://latex.codecogs.com/gif.latex?g(x,\theta&space;)=\sum_{j=1}^{n}\theta_jf_j(x)) - для задачи восстановления регрессии, ![](https://latex.codecogs.com/gif.latex?Y=\mathbb{R}) 
- ![](https://latex.codecogs.com/gif.latex?g(x,\theta&space;)=sign\sum_{j=1}^{n}\theta_jf_j(x)) -для задач классификации ![](https://latex.codecogs.com/gif.latex?Y%3D%5Cleft%20%5C%7B%20-1%2C&plus;1%20%5Cright%20%5C%7D) 
>Признаки могут быть не только измерения, но и функции от них (выше)

Пример: если будем классифицировать выбокру из второго измерения (х_i,у_i) и введем n признаков, так чтобы ![](https://latex.codecogs.com/gif.latex?f_j(x)=x^{j-1}) по формулам g, то получим полином степени n-1.
Процесс подбора оптимального параметра модели ![](https://latex.codecogs.com/gif.latex?\theta) по обучающей выборке ![](https://latex.codecogs.com/gif.latex?X^l) называют настройкой (fitting) или обучением (training, learning) алгоритма ![](https://latex.codecogs.com/gif.latex?a\in&space;A).

**Методом обучения** называется отображение ![](https://latex.codecogs.com/gif.latex?\mu:(X\times&space;Y)^l\rightarrow&space;A), которое произвольной конечной выборке ![](https://latex.codecogs.com/gif.latex?X^l) ставит в соответствие алгоритм a: X → Y . Говорят также, что метод ![](https://latex.codecogs.com/gif.latex?\mu) строит алгоритм a по выборке ![](https://latex.codecogs.com/gif.latex?X^l). Метод обучения, как и сам алгоритм a, должен допускать эффективную программную реализацию.
Итак, в задачах обучения по прецедентам чётко различаются два этапа:
- на этапе обучения метод ![](https://latex.codecogs.com/gif.latex?\mu) по выборке ![](https://latex.codecogs.com/gif.latex?X^l) строит алгоритм ![](https://latex.codecogs.com/gif.latex?a=\mu&space;(X^l));
- на этапе применения алгоритму a подаются на вход новые объекты x, в общем
случае отличные от обучающих, для получения ответов y = a(x).

Этап обучения наиболее сложен. Как правило, он сводится к поиску параметров
модели, доставляющих оптимальное значение заданному функционалу качества.

#### Функционал качества
Функция потерь (loss function) — это неотрицательная функция L (a, x), характеризующая величину ошибки алгоритма a на объекте x. Если L (a, x) = 0, то ответ a(x) называется корректным.
Функционал качества алгоритма ![](https://latex.codecogs.com/gif.latex?a) на выборке ![](https://latex.codecogs.com/gif.latex?X^l):

![](https://latex.codecogs.com/gif.latex?Q(a,&space;X^l)=\frac{1}{l}\sum_{i=1}^{l}\mathfrak{L}(a,x_i))

Функционал Q называют также функционалом средних потерь или эмпирическим риском, так как он вычисляется по эмпирическим данным (xi, yi).
>Эмпирические данные — данные, полученные путём наблюдения или эксперимента.

Функция потерь, принимающая только значения 0 и 1, называется бинарной.
В этом случае L(a, x)=1 означает, что алгоритм a допускает ошибку на объекте x,
а функционал Q называется частотой ошибок алгоритма a на выборке ![](https://latex.codecogs.com/gif.latex?X^l).
Наиболее часто используются следующие функции потерь, при ![](https://latex.codecogs.com/gif.latex?Y\subseteq&space;\mathbb{R}):
- ![](https://latex.codecogs.com/gif.latex?\mathfrak{L}(a,x)=\left&space;[&space;a(x)\neq&space;y^*(x)&space;\right&space;]) — индикатор ошибки, обычно применяется в задачах
классификации (ответ будет 0 или 1);
- ![](https://latex.codecogs.com/gif.latex?\mathfrak{L}(a,x)=|&space;a(x)-&space;y^*(x)&space;|) — отклонение от правильного ответа; функционал Q называется средней ошибкой алгоритма ![](https://latex.codecogs.com/gif.latex?a) на выборке ![](https://latex.codecogs.com/gif.latex?X^l);
- ![](https://latex.codecogs.com/gif.latex?%5Cmathfrak%7BL%7D%28a%2Cx%29%3D%28a%28x%29-y%5E*%28x%29%29%5E2) — квадратичная функция потерь; функционал Q называется средней квадратичной ошибкой алгоритма ![](https://latex.codecogs.com/gif.latex?a) на выборке ![](https://latex.codecogs.com/gif.latex?X^l); обычно применяется в задачах регрессии.

Классический метод обучения, называемый минимизацией эмпирического риска (empirical risk minimization, ERM), заключается в том, чтобы найти в заданной модели A алгоритм ![](https://latex.codecogs.com/gif.latex?a), доставляющий минимальное значение функционалу качества Q на заданной обучающей выборке ![](https://latex.codecogs.com/gif.latex?X^l):
![](https://latex.codecogs.com/gif.latex?\mu&space;(X^l)=\arg&space;\min_{a&space;\in&space;A}&space;Q(a,X^l))
####  Вероятностная постановка задачи обучения
Данные могут быть неточными или неполными, тогда может возникнуть случай, когда одному и тому же описанию соответствуют различные объекты и различные ответы ![](https://latex.codecogs.com/gif.latex?\Rightarrow) ![](https://latex.codecogs.com/gif.latex?y^*(x)) (целевая зависимость) не является функцией (или просто неизвестна). 

РЕШЕНИЕ: устранение некорректности с помощью вероятностной постановка задачи. Вместо неизвестной целевой зависимости предполагаем, что  ![](https://latex.codecogs.com/gif.latex?\exists) неизвестное вероятностное распределение с плотностью  ![](https://latex.codecogs.com/gif.latex?p(x,y)=p(x)p(y|x)),![](https://latex.codecogs.com/gif.latex?p%28y%7Cx%29%3D%5Cdelta%28y-y%5E*%28x%29%29)  из которого случайно и независимо выбираются ![](https://latex.codecogs.com/gif.latex?l) наблюдений ![](https://latex.codecogs.com/gif.latex?X%5El%3D%28x_i%2Cy_i%29_%7Bi%3D1%7D%5El).

>![](https://latex.codecogs.com/gif.latex?\delta) - дельта-функция:
![](https://latex.codecogs.com/gif.latex?%5Cdelta%28x%29%3D%5Cleft%5C%7B%5Cbegin%7Bmatrix%7D%20&plus;%5Cinfty%20%2C%20%26%20x%3D0%20%5C%5C%200%2C%26%20x%5Cneq%200%20%5Cend%7Bmatrix%7D%5Cright.)

Такие выборки называются простыми или случайными одинаково распределёнными.
Вероятностная постановка задачи считается более общей, так как функциональную зависимость y.

#### Принцип максимума правдоподобия
Задаётся модель совместной плотности распределения объектов и ответов ![](https://latex.codecogs.com/gif.latex?\varphi(x,y,\theta)),
аппроксимирующая неизвестную плотность ![](https://latex.codecogs.com/gif.latex?p(x,y)).

>Аппроксимация - научный метод, состоящий в замене одних объектов другими, в каком-то смысле близкими к исходным, но более простыми

Затем определяется значение параметра ![](https://latex.codecogs.com/gif.latex?\theta), при котором выборка данных ![](https://latex.codecogs.com/gif.latex?X^l) максимально правдоподобна, то есть наилучшим образом согласуется с моделью плотности.
Если наблюдения в выборке ![](https://latex.codecogs.com/gif.latex?X^l) независимы, то совместная плотность распределения всех наблюдений равна произведению плотностей p(x, y) в каждом наблюдении. Подставляя вместо p(x, y) модель плотности ![](https://latex.codecogs.com/gif.latex?\varphi(x,y,\theta)) (аппроксимация), получаем функцию правдоподобия (likelihood):
![](https://latex.codecogs.com/gif.latex?L%28%5Ctheta%2C%20X%5El%29%3D%5Cprod_%7Bi%3D1%7D%5E%7Bl%7D%5Cvarphi%20%28x_i%2Cy_i%2C%5Ctheta%29.)

ПРИНЦИП МАКСИМУМА ПРАВДОПОДОБИЯ: чем выше значение правдоподобия, тем лучше выборка согласуется с моделью ![](https://latex.codecogs.com/gif.latex?\Rightarrow) найти такое значение ![](https://latex.codecogs.com/gif.latex?\theta), при котором значение функции правдоподобия максимально. Далее алгоритм строится по плотности ![](https://latex.codecogs.com/gif.latex?\varphi(x,y,\theta)).
#### Связь максимизации правдоподобия с минимизацией эмпирического риска
Вместо максимизации L удобнее минимизировать функционал  −ln(L), по объектам выборки из произведения превратится в сумму ( по свойствам логарифмов):

![](https://latex.codecogs.com/gif.latex?-%5Cln%20L%28%5Ctheta%2C%20X%5El%29%3D-%5Csum_%7Bi%3D1%7D%5E%7Bl%7D%5Cln%20%5Cvarphi%20%28x_i%2Cy_i%2C%5Ctheta%20%29%5Crightarrow%20%5Cmin_%7B%5Ctheta%20%7D)

Этот функционал совпадает с функционалом эмпирического риска, если определить вероятностную функцию потерь ![](https://latex.codecogs.com/gif.latex?\mathfrak{L}(a_\theta,&space;x)=-l\ln&space;\varphi&space;(x,y,\theta&space;))
Такое определение потери вполне естественно — чем хуже пара (xi, yi) согласуется с моделью ![](https://latex.codecogs.com/gif.latex?\varphi), тем меньше значение плотности  ![](https://latex.codecogs.com/gif.latex?\varphi(x_i,y_i,\theta)) и выше величина потери ![](https://latex.codecogs.com/gif.latex?\mathfrak{L}(a_\theta,&space;x)).
Верно и обратное — для многих функций потерь возможно подобрать модель плотности ![](https://latex.codecogs.com/gif.latex?\varphi(x,y,\theta))  таким образом, чтобы минимизация эмпирического риска была эквивалентна максимизации правдоподобия.
#### Проблема переобучения и понятие обобщающей способности
Минимум функционала качества алгоритма не гарантирует хороший результат для произвольной контрольной выборки. Когда качество работы алгоритма на новых объектах, не вошедших в состав обучения, оказывается существенно хуже, чем на обучающей выборке, говорят об эффекте **переобучения (overtraining) или переподгонки (overfitting)**.
>вероятность ошибки на тестовой выборке ![](https://latex.codecogs.com/gif.latex?>) (существенно выше) чем средняя ошибка на обучающей выборке.  
Переобучение возникает при использовании избыточно сложных моделей.

По сути алгоритм просто запоминает обучающуюся выборку ![](https://latex.codecogs.com/gif.latex?x_i\in&space;X^l): берет объект х и сравнивает с обучающей выборкой ![](https://latex.codecogs.com/gif.latex?x_i), если ![](https://latex.codecogs.com/gif.latex?x=x_i) - алгоритм выдаст правильный ответ, иначе - произвольный ответ.Однако этот алгоритм не способен восстановить зависимость вне материала обучения. Отсюда вывод: для успешного обучения необходимо не только запоминать, но и обобщать.

**Обобщающая способность (generalization ability, generalization performance).** Говорят, что алгоритм обучения обладает способностью к обобщению, если вероятность ошибки на тестовой выборке достаточно мала или хотя бы предсказуема, то есть не сильно отличается от ошибки на обучающей выборке. 
>вероятность ошибки на тестовой выборке ![](https://latex.codecogs.com/gif.latex?\approx) вероятность ошибки на обучающей выборке

**Недообучение** — нежелательное явление, возникающее при решении задач обучения по прецедентам, когда алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке. 
>вероятность ошибки на обучающей выборке ![](https://latex.codecogs.com/gif.latex?>&space;\varepsilon)
Недообучение возникает при использовании недостаточно сложных моделей.

Разобьём полную выборку ![](https://latex.codecogs.com/gif.latex?X^L) на две непересекающихся подвыборки: обучающую ![](https://latex.codecogs.com/gif.latex?X^l) и контрольную ![](https://latex.codecogs.com/gif.latex?X^k) , ![](https://latex.codecogs.com/gif.latex?L=k+l).
**Переобученностью** алгоритма ![](https://latex.codecogs.com/gif.latex?a=\mu(X^l)) на паре выборок ![](https://latex.codecogs.com/gif.latex?(X^l,X^k)) будем называть разность  ![](https://latex.codecogs.com/gif.latex?\delta&space;(\mu,&space;X^l,&space;X^k)=Q(a,X^k)-Q(a,X^l)).
Функционал **полного скользящего контроля (complete cross-validation)** определяется как средняя частота ошибок на контрольных подвыборках:
![](https://latex.codecogs.com/gif.latex?CVV(\mu,&space;X^L)=\frac{1}{N}\sum_{n=1}^{N}Q^k_n)
> ![](https://latex.codecogs.com/gif.latex?N) - от множества разбиений ![](https://latex.codecogs.com/gif.latex?%5Cleft%20%5C%7B%201%2C%5Ccdots%20%2C%20N%20%5Cright%20%5C%7D)
n - номер разбиения
![](https://latex.codecogs.com/gif.latex?Q%5Ek_n%3DQ%28%5Cmu%20%28X%5El_n%29%2C%20X%5Ek_n%29)
![](https://latex.codecogs.com/gif.latex?Q%5El_n%3DQ%28%5Cmu%20%28X%5El_n%29%2C%20X%5El_n%29)

ПРОБЛЕМА: разброс величины ![](https://latex.codecogs.com/gif.latex?Q^k_n) (частота ошбок мала, но значения ![](https://latex.codecogs.com/gif.latex?Q^k_n) большие для разбиения)


РЕШЕНИЕ: применение функции распределения ![](https://latex.codecogs.com/gif.latex?R%28%5Cmu%2C%20X%5El%29%3DP_n%5Cleft%20%5C%7B%20Q%5Ek_n%3E%5Cvarepsilon%20%5Cright%20%5C%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bn%3D1%7D%5E%7BN%7D%5Cleft%20%5B%20Q%5Ek_n%3E%5Cvarepsilon%20%5Cright%20%5D)


+ЕЩЁ РЕШЕНИЕ: иногда удобно расчитывать величину переобученности ![](https://latex.codecogs.com/gif.latex?Q_%5Cvarepsilon%20%28%5Cmu%2C%20X%5El%29%3DP_n%5Cleft%20%5C%7B%20%5Cdelta%20%28%5Cmu%2C%20X%5El_n%2CX%5Ek_n%29%3E%5Cvarepsilon%20%5Cright%20%5C%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bn%3D1%7D%5E%7BN%7D%5Cleft%20%5B%20Q%5Ek_n-Q%5El_n%3E%5Cvarepsilon%20%5Cright%20%5D)

Функционал ![](https://latex.codecogs.com/gif.latex?Q_\varepsilon) является кусочно-постоянной невозрастающей функцией параметра ![](https://latex.codecogs.com/gif.latex?\varepsilon). Пусть имеется его оценка сверху ![](https://latex.codecogs.com/gif.latex?Q_\varepsilon&space;\leqslant&space;\eta&space;(\varepsilon&space;)), где ![](https://latex.codecogs.com/gif.latex?\eta&space;(\varepsilon&space;)) — монотонно убывающая функция. Функция ![](https://latex.codecogs.com/gif.latex?\varepsilon(\eta)), обратная к ![](https://latex.codecogs.com/gif.latex?\eta&space;(\varepsilon&space;)), также монотонно убывающая. Тогда ![](https://latex.codecogs.com/gif.latex?Q_\varepsilon) эквивалентно утверждению, что для данного метода и выборки с вероятностью, не меньшей ![](https://latex.codecogs.com/gif.latex?1-\eta), выполняется неравенство ![](https://latex.codecogs.com/gif.latex?Q_n^k\leqslant&space;Q_n^l&plus;\varepsilon(\eta)). В этом случае говорят, что обучение ***состоятельно*** с точностью ![](https://latex.codecogs.com/gif.latex?\varepsilon) и надёжностью ![](https://latex.codecogs.com/gif.latex?\eta).

- Контроль по отдельным объектам (leave one out CV): k = 1
![](https://latex.codecogs.com/gif.latex?LOO%28%5Cmu%2C%20X%5EL%29%3D%5Cfrac%7B1%7D%7BL%7D%5Csum_%7Bi%3D1%7D%5E%7BL%7DQ%28X%5EL%20%5Csetminus%20%5Cleft%20%5C%7B%20x_i%20%5Cright%20%5C%7D%2C%5Cleft%20%5C%7B%20x_i%20%5Cright%20%5C%7D%29)


Проблема: ресурсоемкость

- Контроль по q блокам (q-fold CV): случайное разбиение ![](https://latex.codecogs.com/gif.latex?X%5EL%3DX%5E%7Bl_1%7D_1%5Ccup%20%5Ccdots%20%5Ccup%20X%5E%7Bl_q%7D_q) на q блоков (почти) равной длины
![](https://latex.codecogs.com/gif.latex?CV_q%28%5Cmu%2C%20X%5EL%29%3D%5Cfrac%7B1%7D%7Bq%7D%5Csum_%7Bi%3D1%7D%5E%7Bq%7DQ%28X%5EL%20%5Csetminus%20X%5E%7Bl_i%7D_i%2CX%5E%7Bl_i%7D_i%29)

Проблема:
- -  оценка существенно зависит от разбиения на блоки;
- - каждый объект лишь один раз участвует в контроле.


- Контроль t раз по q блокам (t×q-fold CV) — стандарт «де факто» для тестирования методов обучения.
Выборка X^L разбивается t раз случайным образом на q блоков
![](https://latex.codecogs.com/gif.latex?X%5EL%3DX%5E%7Bl_1%7D_%7Bs1%7D%5Ccup%20%5Ccdots%20%5Ccup%20X%5E%7Bl_q%7D_%7Bsq%7D%2C%5C%3B%20s%3D%5Coverline%7B1%2Ct%7D%2C%20%5C%3B%20l_1&plus;%5Ccdots%20&plus;l_q%3DL)
![](https://latex.codecogs.com/gif.latex?CV_%7Bt%5Ctimes%20q%7D%28%5Cmu%2C%20X%5EL%29%3D%5Cfrac%7B1%7D%7Bt%7D%5Csum_%7Bs%3D1%7D%5E%7Bt%7D%5Cfrac%7B1%7D%7Bq%7D%5Csum_%7Bn%3D1%7D%5E%7Bq%7DQ%28X%5EL%5Csetminus%20X%5E%7Bl_n%7D_%7Bsn%7D%2CX%5E%7Bl_n%7D_%7Bsn%7D%29)

Преимущества t×q-fold CV:
- - увеличением t можно улучшать точность оценки(компромисс между точностью и временем вычислений);
- - каждый объект участвует в контроле ровно t раз;
- - можно вычислять доверительные интервалы (при t > или прблизительно 20)

## 2. Модель алгоритмов и метод обучения. Функционал качества и функция потерь
 Моделью алгоритмов называется параметрическое семейство отображений ![](https://latex.codecogs.com/gif.latex?A%3D%5Cleft%20%5C%7B%20g%28x%2C%5Ctheta%29%20%7C%20%5Ctheta%20%5Cin%20%5CTheta%20%5Cright%20%5C%7D%2C%20%5C%3A%20g%3AX%5Ctimes%20%5CTheta%20%5Crightarrow%20Y), g — некоторая фиксированная функция, ![](https://latex.codecogs.com/gif.latex?\Theta) — множество допустимых значений параметра ![](https://latex.codecogs.com/gif.latex?\theta), называемое пространством параметров или пространством поиска (search space).

Линейные модели с вектором параметров ![](https://latex.codecogs.com/gif.latex?%5Ctheta%3D%5Cleft%20%28%5Ctheta_1%2C%5Ccdots%20%2C%20%5Ctheta_n%20%5Cright%20%29%5Cin%20%5CTheta%20%3D%5Cmathbb%7BR%7D%5En):

- ![](https://latex.codecogs.com/gif.latex?g(x,\theta&space;)=\sum_{j=1}^{n}\theta_jf_j(x)) - для задачи восстановления регрессии, ![](https://latex.codecogs.com/gif.latex?Y=\mathbb{R}) 
- ![](https://latex.codecogs.com/gif.latex?g(x,\theta&space;)=sign\sum_{j=1}^{n}\theta_jf_j(x)) -для задач классификации ![](https://latex.codecogs.com/gif.latex?Y%3D%5Cleft%20%5C%7B%20-1%2C&plus;1%20%5Cright%20%5C%7D) 
>Признаки могут быть не только измерения, но и функции от них (выше)

Пример: если будем классифицировать выбокру из второго измерения (х_i,у_i) и введем n признаков, так чтобы ![](https://latex.codecogs.com/gif.latex?f_j(x)=x^{j-1}) по формулам g, то получим полином степени n-1.
Процесс подбора оптимального параметра модели ![](https://latex.codecogs.com/gif.latex?\theta) по обучающей выборке ![](https://latex.codecogs.com/gif.latex?X^l) называют настройкой (fitting) или обучением (training, learning) алгоритма ![](https://latex.codecogs.com/gif.latex?a\in&space;A).

**Методом обучения** называется отображение ![](https://latex.codecogs.com/gif.latex?\mu:(X\times&space;Y)^l\rightarrow&space;A), которое произвольной конечной выборке ![](https://latex.codecogs.com/gif.latex?X^l) ставит в соответствие алгоритм a: X → Y . Говорят также, что метод ![](https://latex.codecogs.com/gif.latex?\mu) строит алгоритм a по выборке ![](https://latex.codecogs.com/gif.latex?X^l). Метод обучения, как и сам алгоритм a, должен допускать эффективную программную реализацию.
Итак, в задачах обучения по прецедентам чётко различаются два этапа:
- на этапе обучения метод ![](https://latex.codecogs.com/gif.latex?\mu) по выборке ![](https://latex.codecogs.com/gif.latex?X^l) строит алгоритм ![](https://latex.codecogs.com/gif.latex?a=\mu&space;(X^l));
- на этапе применения алгоритму a подаются на вход новые объекты x, в общем
случае отличные от обучающих, для получения ответов y = a(x).

Этап обучения наиболее сложен. Как правило, он сводится к поиску параметров
модели, доставляющих оптимальное значение заданному функционалу качества.

#### Функционал качества
Функция потерь (loss function) — это неотрицательная функция L (a, x), характеризующая величину ошибки алгоритма a на объекте x. Если L (a, x) = 0, то ответ a(x) называется корректным.
Функционал качества алгоритма ![](https://latex.codecogs.com/gif.latex?a) на выборке ![](https://latex.codecogs.com/gif.latex?X^l):

![](https://latex.codecogs.com/gif.latex?Q(a,&space;X^l)=\frac{1}{l}\sum_{i=1}^{l}\mathfrak{L}(a,x_i))

Функционал Q называют также функционалом средних потерь или эмпирическим риском, так как он вычисляется по эмпирическим данным (xi, yi).
>Эмпирические данные — данные, полученные путём наблюдения или эксперимента.

Функция потерь, принимающая только значения 0 и 1, называется бинарной.
В этом случае L(a, x)=1 означает, что алгоритм a допускает ошибку на объекте x,
а функционал Q называется частотой ошибок алгоритма a на выборке ![](https://latex.codecogs.com/gif.latex?X^l).
Наиболее часто используются следующие функции потерь, при ![](https://latex.codecogs.com/gif.latex?Y\subseteq&space;\mathbb{R}):
- ![](https://latex.codecogs.com/gif.latex?\mathfrak{L}(a,x)=\left&space;[&space;a(x)\neq&space;y^*(x)&space;\right&space;]) — индикатор ошибки, обычно применяется в задачах
классификации (ответ будет 0 или 1);
- ![](https://latex.codecogs.com/gif.latex?\mathfrak{L}(a,x)=|&space;a(x)-&space;y^*(x)&space;|) — отклонение от правильного ответа; функционал Q называется средней ошибкой алгоритма ![](https://latex.codecogs.com/gif.latex?a) на выборке ![](https://latex.codecogs.com/gif.latex?X^l);
- ![](https://latex.codecogs.com/gif.latex?%5Cmathfrak%7BL%7D%28a%2Cx%29%3D%28a%28x%29-y%5E*%28x%29%29%5E2) — квадратичная функция потерь; функционал Q называется средней квадратичной ошибкой алгоритма ![](https://latex.codecogs.com/gif.latex?a) на выборке ![](https://latex.codecogs.com/gif.latex?X^l); обычно применяется в задачах регрессии.

Классический метод обучения, называемый минимизацией эмпирического риска (empirical risk minimization, ERM), заключается в том, чтобы найти в заданной модели A алгоритм ![](https://latex.codecogs.com/gif.latex?a), доставляющий минимальное значение функционалу качества Q на заданной обучающей выборке ![](https://latex.codecogs.com/gif.latex?X^l):
![](https://latex.codecogs.com/gif.latex?\mu&space;(X^l)=\arg&space;\min_{a&space;\in&space;A}&space;Q(a,X^l))

## 3. Проблема переобучения и понятие обобщающей способности. Эмпирические оценки обобщающей способности. Разновидности скользящего контроля

Минимум функционала качества алгоритма не гарантирует хороший результат для произвольной контрольной выборки. Когда качество работы алгоритма на новых объектах, не вошедших в состав обучения, оказывается существенно хуже, чем на обучающей выборке, говорят об эффекте **переобучения (overtraining) или переподгонки (overfitting)**.
>вероятность ошибки на тестовой выборке ![](https://latex.codecogs.com/gif.latex?>) (существенно выше) чем средняя ошибка на обучающей выборке.  
Переобучение возникает при использовании избыточно сложных моделей.

По сути алгоритм просто запоминает обучающуюся выборку ![](https://latex.codecogs.com/gif.latex?x_i\in&space;X^l): берет объект х и сравнивает с обучающей выборкой ![](https://latex.codecogs.com/gif.latex?x_i), если ![](https://latex.codecogs.com/gif.latex?x=x_i) - алгоритм выдаст правильный ответ, иначе - произвольный ответ.Однако этот алгоритм не способен восстановить зависимость вне материала обучения. Отсюда вывод: для успешного обучения необходимо не только запоминать, но и обобщать.

**Обобщающая способность (generalization ability, generalization performance).** Говорят, что алгоритм обучения обладает способностью к обобщению, если вероятность ошибки на тестовой выборке достаточно мала или хотя бы предсказуема, то есть не сильно отличается от ошибки на обучающей выборке. 
>вероятность ошибки на тестовой выборке ![](https://latex.codecogs.com/gif.latex?\approx) вероятность ошибки на обучающей выборке

**Недообучение** — нежелательное явление, возникающее при решении задач обучения по прецедентам, когда алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке. 
>вероятность ошибки на обучающей выборке ![](https://latex.codecogs.com/gif.latex?>&space;\varepsilon)
Недообучение возникает при использовании недостаточно сложных моделей.

Разобьём полную выборку ![](https://latex.codecogs.com/gif.latex?X^L) на две непересекающихся подвыборки: обучающую ![](https://latex.codecogs.com/gif.latex?X^l) и контрольную ![](https://latex.codecogs.com/gif.latex?X^k) , ![](https://latex.codecogs.com/gif.latex?L=k+l).
**Переобученностью** алгоритма ![](https://latex.codecogs.com/gif.latex?a=\mu(X^l)) на паре выборок ![](https://latex.codecogs.com/gif.latex?(X^l,X^k)) будем называть разность  ![](https://latex.codecogs.com/gif.latex?\delta&space;(\mu,&space;X^l,&space;X^k)=Q(a,X^k)-Q(a,X^l)).
Функционал **полного скользящего контроля (complete cross-validation)** определяется как средняя частота ошибок на контрольных подвыборках:
![](https://latex.codecogs.com/gif.latex?CVV(\mu,&space;X^L)=\frac{1}{N}\sum_{n=1}^{N}Q^k_n)
> ![](https://latex.codecogs.com/gif.latex?N) - от множества разбиений ![](https://latex.codecogs.com/gif.latex?%5Cleft%20%5C%7B%201%2C%5Ccdots%20%2C%20N%20%5Cright%20%5C%7D)
n - номер разбиения
![](https://latex.codecogs.com/gif.latex?Q%5Ek_n%3DQ%28%5Cmu%20%28X%5El_n%29%2C%20X%5Ek_n%29)
![](https://latex.codecogs.com/gif.latex?Q%5El_n%3DQ%28%5Cmu%20%28X%5El_n%29%2C%20X%5El_n%29)

ПРОБЛЕМА: разброс величины ![](https://latex.codecogs.com/gif.latex?Q^k_n) (частота ошбок мала, но значения ![](https://latex.codecogs.com/gif.latex?Q^k_n) большие для разбиения)


РЕШЕНИЕ: применение функции распределения ![](https://latex.codecogs.com/gif.latex?R%28%5Cmu%2C%20X%5El%29%3DP_n%5Cleft%20%5C%7B%20Q%5Ek_n%3E%5Cvarepsilon%20%5Cright%20%5C%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bn%3D1%7D%5E%7BN%7D%5Cleft%20%5B%20Q%5Ek_n%3E%5Cvarepsilon%20%5Cright%20%5D)


+ЕЩЁ РЕШЕНИЕ: иногда удобно расчитывать величину переобученности ![](https://latex.codecogs.com/gif.latex?Q_%5Cvarepsilon%20%28%5Cmu%2C%20X%5El%29%3DP_n%5Cleft%20%5C%7B%20%5Cdelta%20%28%5Cmu%2C%20X%5El_n%2CX%5Ek_n%29%3E%5Cvarepsilon%20%5Cright%20%5C%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bn%3D1%7D%5E%7BN%7D%5Cleft%20%5B%20Q%5Ek_n-Q%5El_n%3E%5Cvarepsilon%20%5Cright%20%5D)

Функционал ![](https://latex.codecogs.com/gif.latex?Q_\varepsilon) является кусочно-постоянной невозрастающей функцией параметра ![](https://latex.codecogs.com/gif.latex?\varepsilon). Пусть имеется его оценка сверху ![](https://latex.codecogs.com/gif.latex?Q_\varepsilon&space;\leqslant&space;\eta&space;(\varepsilon&space;)), где ![](https://latex.codecogs.com/gif.latex?\eta&space;(\varepsilon&space;)) — монотонно убывающая функция. Функция ![](https://latex.codecogs.com/gif.latex?\varepsilon(\eta)), обратная к ![](https://latex.codecogs.com/gif.latex?\eta&space;(\varepsilon&space;)), также монотонно убывающая. Тогда ![](https://latex.codecogs.com/gif.latex?Q_\varepsilon) эквивалентно утверждению, что для данного метода и выборки с вероятностью, не меньшей ![](https://latex.codecogs.com/gif.latex?1-\eta), выполняется неравенство ![](https://latex.codecogs.com/gif.latex?Q_n^k\leqslant&space;Q_n^l&plus;\varepsilon(\eta)). В этом случае говорят, что обучение ***состоятельно*** с точностью ![](https://latex.codecogs.com/gif.latex?\varepsilon) и надёжностью ![](https://latex.codecogs.com/gif.latex?\eta).

- Контроль по отдельным объектам (leave one out CV): k = 1
![](https://latex.codecogs.com/gif.latex?LOO%28%5Cmu%2C%20X%5EL%29%3D%5Cfrac%7B1%7D%7BL%7D%5Csum_%7Bi%3D1%7D%5E%7BL%7DQ%28X%5EL%20%5Csetminus%20%5Cleft%20%5C%7B%20x_i%20%5Cright%20%5C%7D%2C%5Cleft%20%5C%7B%20x_i%20%5Cright%20%5C%7D%29)


Проблема: ресурсоемкость

- Контроль по q блокам (q-fold CV): случайное разбиение ![](https://latex.codecogs.com/gif.latex?X%5EL%3DX%5E%7Bl_1%7D_1%5Ccup%20%5Ccdots%20%5Ccup%20X%5E%7Bl_q%7D_q) на q блоков (почти) равной длины
![](https://latex.codecogs.com/gif.latex?CV_q%28%5Cmu%2C%20X%5EL%29%3D%5Cfrac%7B1%7D%7Bq%7D%5Csum_%7Bi%3D1%7D%5E%7Bq%7DQ%28X%5EL%20%5Csetminus%20X%5E%7Bl_i%7D_i%2CX%5E%7Bl_i%7D_i%29)

Проблема:
- -  оценка существенно зависит от разбиения на блоки;
- - каждый объект лишь один раз участвует в контроле.


- Контроль t раз по q блокам (t×q-fold CV) — стандарт «де факто» для тестирования методов обучения.
Выборка X^L разбивается t раз случайным образом на q блоков
![](https://latex.codecogs.com/gif.latex?X%5EL%3DX%5E%7Bl_1%7D_%7Bs1%7D%5Ccup%20%5Ccdots%20%5Ccup%20X%5E%7Bl_q%7D_%7Bsq%7D%2C%5C%3B%20s%3D%5Coverline%7B1%2Ct%7D%2C%20%5C%3B%20l_1&plus;%5Ccdots%20&plus;l_q%3DL)
![](https://latex.codecogs.com/gif.latex?CV_%7Bt%5Ctimes%20q%7D%28%5Cmu%2C%20X%5EL%29%3D%5Cfrac%7B1%7D%7Bt%7D%5Csum_%7Bs%3D1%7D%5E%7Bt%7D%5Cfrac%7B1%7D%7Bq%7D%5Csum_%7Bn%3D1%7D%5E%7Bq%7DQ%28X%5EL%5Csetminus%20X%5E%7Bl_n%7D_%7Bsn%7D%2CX%5E%7Bl_n%7D_%7Bsn%7D%29)

Преимущества t×q-fold CV:
- - увеличением t можно улучшать точность оценки(компромисс между точностью и временем вычислений);
- - каждый объект участвует в контроле ровно t раз;
- - можно вычислять доверительные интервалы (при t > или прблизительно 20)

## 4-6 Метрические алгоритмы классификации
 
 Метрический классификатор (similarity-based classifier) — алгоритм классификации, основанный на вычислении оценок сходства между объектами. Метрические классификаторы опираются на **гипотезу компактности**, которая предполагает, что схожие объекты чаще лежат в одном классе, чем в разных. Это означает, что граница между классами имеет достаточно простую форму, и классы образуют компактно локализованные области в пространстве объектов. Заметим, что в математическом анализе компактными называются ограниченные замкнутые множества.
 ПРОБЛЕМА ВЫБОРА МЕТРИКИ:
 - редко когда работает евклидова метрика ( выбор евклидовой ничем не обоснован, просто проще)
 - нормирование (нужно ли?)
 - проблема проклятия размерности: больше размерность - меньше достоверность работы алгоритма ([тут подробней про саму проблему](https://vc.ru/ml/137209-proklyate-razmernosti))
  

## 4. Метрические алгоритмы классификации: алгоритмы ближайших соседей
#### !!!! Зависит от ранга соседа!!!!!
###  Обобщённый метрический классификатор
Для произвольного объекта ![](https://latex.codecogs.com/gif.latex?u&space;\in&space;X) расположим элементы обучающей выборки ![](https://latex.codecogs.com/gif.latex?x_1,\dots,x_l) в порядке возрастания расстояний до ![](https://latex.codecogs.com/gif.latex?u):

![](https://latex.codecogs.com/gif.latex?%5Crho%20%28u%2Cx_u%5E%7B%281%29%7D%29%5Cleqslant%20%5Crho%20%28u%2Cx_u%5E%7B%282%29%7D%29%5Cleqslant%20%5Ccdots%20%5Cleqslant%20%5Crho%20%28u%2Cx_u%5E%7B%28l%29%7D%29)

где через ![](https://latex.codecogs.com/gif.latex?x_u^{(i)}) обозначается i-й сосед объекта u.

**Метрический алгоритм классификации** с обучающей выборкой ![](https://latex.codecogs.com/gif.latex?X^l) относит объект ![](https://latex.codecogs.com/gif.latex?u) к тому классу y, для которого суммарный вес ближайших обучающих объектов ![](https://latex.codecogs.com/gif.latex?\Gamma_y(u,X^l)) максимален:

![](https://latex.codecogs.com/gif.latex?a%28u%2C%20X%5El%29%3D%5Carg%20%5Cmax_%7By%5Cin%20Y%7D%5CGamma_y%28u%2CX%5El%29%3B%5C%3B%20%5C%3A%20%5C%3A%20%5C%3A%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3A%20%5C%3A%20%5C%3A%20%5C%3A%20%5C%3A%20%5CGamma_y%28u%2CX%5El%29%3D%5Csum_%7Bi%3D1%7D%5E%7Bl%7D%5Cleft%20%5B%20y_u%5E%7B%28i%29%7D%3Dy%20%5Cright%20%5Dw%28i%2Cu%29)

где весовая функция w(i, u) оценивает степень важности i-го соседа для классификации объекта u. Функция ![](https://latex.codecogs.com/gif.latex?\Gamma_y(u,X^l)) называется оценкой близости объекта u к классу y.

Метрический классификатор определён с точностью до весовой функции w(i, u) (функция w неотрицательна). Обучающая выборка параметр алгоритма а. Алгоритм делает аппроксимацию выборки, причем вычисления не производятся до тех пор, пока не известен объект  u. ---> относится к методам ленивого обучения и методам рассуждения по прецедентам.

### Алгоритм ближайших соседей

Алгоритм ближайшего соседа (nearest neighbor, NN) относит классифицируемый объект ![](https://latex.codecogs.com/gif.latex?u&space;\in&space;X^l) к тому классу, которому принадлежит ближайший обучающий объект:
![](https://latex.codecogs.com/gif.latex?w%28i%2Cu%29%3D%5Bi%3D1%5D%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20a%28u%2CX%5El%29%3Dy_u%5E%7B%281%29%7D)
Преимущество: простота реализации
Недостатки:
- неустойчивость к погрешностям (выбрсы повлияют на работу)
- отсутствие параметров, которые можно было настраивать по метрике. (алгоритм зависит от того, насколько удачно выбрана метрика)
- низкое качество классификации

### Алгоритм k ближайших соседей (k nearest neighbors, kNN). 
Чтобы сгладить влияние выбросов, будем относить объект u к тому классу, элементов которого окажется больше среди k ближайших соседей ![](https://latex.codecogs.com/gif.latex?x_u%5E%7B%28i%29%7D%2C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20i%3D1%2C%5Ccdots%20%2Ck%3B):

![](https://latex.codecogs.com/gif.latex?w%28i%2Cu%29%3D%5Cleft%20%5B%20i%5Cleqslant%20k%20%5Cright%20%5D%3B%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20a%28u%2CX%5El%2Ck%29%3D%5Carg%5Cmax_%7By%20%5Cin%20Y%7D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Cleft%20%5B%20y_u%5E%7B%28i%29%7D%3Dy%20%5Cright%20%5D)

При k=1 - неустойчив к шуму, при k=l - устойчив и выражается в константу. Оптимальное значение параметра k определяют по критерию скользящего контроля с исключением объектов по одному (leave-one-out, LOO). Для каждого объекта ![](https://latex.codecogs.com/gif.latex?x_i&space;\in&space;X^l) проверяется, правильно ли он классифицируется по своим k ближайшим соседям.

![](https://latex.codecogs.com/gif.latex?LOO%28k%2CX%5El%29%3D%5Csum_%7Bi%3D1%7D%5E%7Bl%7D%5Cleft%20%5B%20a%28x_i%2C%20X%5El%5Csetminus%20%5Cleft%20%5C%7B%20x_i%20%5Cright%20%5C%7D%2Ck%29%5Cneq%20y_i%5Cright%20%5D%5Crightarrow%20%5Cmin_%7Bk%7D)

Альтернатива: каждом классе выбирается k ближайших к u объектов, и объект u относится к тому классу, для которого среднее расстояние до k ближайших соседей минимально.
Достоинство: учёт выбросов ( стараемся их сгладить)
Недостаток: максимум может достигаться на нескольких классах

### Алгоритм k взвешенных ближайших соседей
Вводим убывающую последовательность вещественных весов w_i, задающих вклад i-го соседа в классификацию:

![](https://latex.codecogs.com/gif.latex?w%28i%2Cu%29%3D%5Cleft%20%5B%20i%5Cleqslant%20k%20%5Cright%20%5Dw_i%3B%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20a%28u%2CX%5El%2Ck%29%3D%5Carg%5Cmax_%7By%20%5Cin%20Y%7D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Cleft%20%5B%20y_u%5E%7B%28i%29%7D%3Dy%20%5Cright%20%5Dw_i)
 
выбор ![](https://latex.codecogs.com/gif.latex?w_i) --- эвристика. Возьмем линейно убывающие веса ![](https://latex.codecogs.com/gif.latex?w_i=\frac{k&plus;1-i}{k}) , то неоднозначности также могут возникать, хотя и реже (пример: классов два; первый и четвёртый сосед голосуют за класс 1, второй и третий — за класс 2; суммы голосов совпадают) ---> устранение: введем геометрическую прогрессию ![](https://latex.codecogs.com/gif.latex?w_i=q^i), где знаменатель прогрессии ![](https://latex.codecogs.com/gif.latex?q\in(0,1)) является параметром алгоритма. Его можно подбирать по критерию LOO, аналогично числу соседей k.

Недостатки простейших метрических алгоритмов типа kNN.
- Приходится хранить обучающую выборку целиком. Это приводит к неэффективному расходу памяти и чрезмерному усложнению решающего правила.
При наличии погрешностей (как в исходных данных, так и в модели сходства ρ) это может приводить к понижению точности классификации вблизи границы классов. Имеет смысл отбирать минимальное подмножество эталонных объектов, действительно необходимых для классификации.
- Поиск ближайшего соседа предполагает сравнение классифицируемого объекта со всеми объектами выборки за O(ℓ) операций. Для задач с большими выборками или высокой частотой запросов это может оказаться накладно. Проблема решается с помощью эффективных алгоритмов поиска ближайших соседей, требующих в среднем O(ln ℓ) операций.
- В простейших случаях метрические алгоритмы имеют крайне бедный набор параметров, что исключает возможность настройки алгоритма по данным.

## 5. Метрические алгоритмы классификации: метод парзеновского окна

#### !!! Зависит от расстояния !!!

Введем функция ядра K(z), невозростающую на ![](https://latex.codecogs.com/gif.latex?%5Cleft%26space%3B%5B%26space%3B0%2C%26space%3B%5Cinfty%26space%3B%5Cright%26space%3B%29) Определяем вес с помощью функции ядра K
 
![](https://github.com/Elzara20/university/blob/master/Parzen%20window/parzen_h.jpg)

где значение функции K определяется как расстояние от заданного z до всех объектов выборки деленное на ширину окна. 
>Ядро определяет степень гладкости функции растояния.

Роль играет ширина окна, (по аналогии с количеством ближайших соседей k), чем меньше k-тем хуже класификация, чем больше - то плотность (площадь) выражается в константу. "Окно" — это сферическая окрестность объекта u радиуса h, при попадании в которую обучающий объект xi «голосует» за отнесение объекта u к классу yi.
При h = const:

![](https://latex.codecogs.com/gif.latex?a%28u%2CX%5El%2Ch%29%3D%5Carg%5Cmax_%7By%5Cin%20Y%7D%5Csum_%7Bi%3D1%7D%5E%7Bl%7D%5Cleft%20%5B%20y_u%5E%7B%28i%29%7D%3Dy%20%5Cright%20%5DK%28%5Cfrac%7B%5Crho%28u%2Cx_u%5Ei%29%7D%7Bh%7D%29)

Если выборка неравномерно распределена, (где-то много соседей, где-то вообще нет) то используют окно переменной ширины. Определим h как наибольшее число, при котором ровно k ближайших соседей объекта u получают ненулевые вес:

![](https://latex.codecogs.com/gif.latex?a%28u%2CX%5El%2Ch%29%3D%5Carg%5Cmax_%7By%5Cin%20Y%7D%5Csum_%7Bi%3D1%7D%5E%7Bl%7D%5Cleft%20%5B%20y_u%5E%7B%28i%29%7D%3Dy%20%5Cright%20%5DK%28%5Cfrac%7B%5Crho%28u%2Cx_u%5Ei%29%7D%7B%5Crho%28u%2Cx_u%5E%7Bk&plus;1%7D%29%7D%29)

[ALGORITHM](https://github.com/Elzara20/university/tree/master/Parzen%20window)

## 6. Метрические алгоритмы классификации: метод потенциальных функций.

![](https://latex.codecogs.com/gif.latex?a%28u%2CX%5El%29%3D%5Carg%5Cmax_%7By%20%5Cin%20Y%7D%5Csum_%7Bi%3D1%7D%5E%7Bl%7D%5Cleft%20%5B%20y_i%3Dy%20%5Cright%20%5D%5Cgamma_iK%28%5Cfrac%7B%5Crho%28u%2Cx_i%29%7D%7Bh_i%7D%29%2C%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5Cgamma_i%5Cgeqslant%200%2C%5C%3B%20h_i%3E%200)

По сути, эта формула отличается от последней формулы только тем, что здесь ширина окна ![](https://latex.codecogs.com/gif.latex?h_i) зависит от обучающего объекта ![](https://latex.codecogs.com/gif.latex?x_i), а не от классифицируемого объекта. (благодаря функции ![](https://latex.codecogs.com/gif.latex?\gamma),ядро помещается в каждый обучающий объект ![](https://latex.codecogs.com/gif.latex?x_i) и "притягивает" объект ![](https://latex.codecogs.com/gif.latex?u) к классу ![](https://latex.codecogs.com/gif.latex?y_i), если он попадает в его окрестность радиуса ![](https://latex.codecogs.com/gif.latex?h_i).
АНАЛОГИЯ с электрическим потенциалом. При Y = {−1, +1} обучающие объекты можно понимать как положительные и отрицательные электрические заряды; коэффициенты ![](https://latex.codecogs.com/gif.latex?\gamma_i) — как абсолютную величину этих зарядов; ядро K(z) — как зависимость потенциала от расстояния до заряда; а саму задачу классификации — как ответ на вопрос: какой знак имеет электростатический потенциал в заданной точке пространства ![](https://latex.codecogs.com/gif.latex?u).
Построение потенциалов: если обучающий объект ![](https://latex.codecogs.com/gif.latex?x_i) классифицируется неверно, то потенциал класса ![](https://latex.codecogs.com/gif.latex?y_i) недостаточен в точке ![](https://latex.codecogs.com/gif.latex?x_i), и вес ![](https://latex.codecogs.com/gif.latex?y_i) увеличивается на единицу. (в коде лучше идти не подряд, а в разброс -- выборочно).
+нет нужды хранить данные
-медленно сходится
-центр потенциала в обучающей выборке
-не настраиваются параметры ![](https://latex.codecogs.com/gif.latex?h_i)
-потенциалы просто применяются, не минимизируются.
РЕШЕНИЕ: переход к радиальным базисным функциям (объект ![](https://latex.codecogs.com/gif.latex?u) сравнивается с центрами потенциалов, которые не совпадают с обучающей выборкой)

[ALGORITHM](https://github.com/Elzara20/university/tree/master/Potential%20functions)  

## 7. Понятие отступа объекта. Эталонные объекты. Алгоритм STOLP.
[ТУТ](https://github.com/Elzara20/university/tree/master/STOLP)

## 8. Аппроксимация эмпирического риска. Вероятностная интерпретация. Линейная модель классификации

Рассмотрим задачу классификации с двумя классами Y = {−1, +1}.
Модель алгоритмов: параметрическое семейство отображений a(x, w) = sign f(x, w), где w — вектор параметров. Функция f(x, w) называется *дискриминантной* функцией. (Если f(x, w) > 0, то алгоритм a относит объект x к классу +1, иначе к классу −1 Уравнение f(x, w) = 0 описывает разделяющую поверхность)
Как обычно, задача обучения классификатора a(x, w) заключается в том, чтобы
настроить вектор параметров w, имея обучающую выборку пар X^ℓ.

Величина ![](https://latex.codecogs.com/gif.latex?M_i(w)=y_if(x_i,w)) называется **отступом (margin)** объекта ![](https://latex.codecogs.com/gif.latex?x_i) относительно алгоритма классификации ![](https://latex.codecogs.com/gif.latex?a(x,w)=\textrm{sign}f(x,w)).
Если отступ меньше нуля - алгоритм допускает ошибку.

АППРОКСИМАЦИЯ (суть - применяем число ошибок на обучающей выборке в функции потерь, а не величину ошибки алгоритма ):
![](https://latex.codecogs.com/gif.latex?\mathfrak{L}(M))  монотонно невозрастающая функция отступа, мажорирующая пороговую функцию потерь: ![](https://latex.codecogs.com/gif.latex?\left&space;[&space;M<0&space;\right&space;]\leqslant&space;\mathfrak{L}(M)).


![](https://latex.codecogs.com/gif.latex?Q%28w%2CX%5El%29%3D%5Csum_%7Bi%3D1%7D%5E%7Bl%7D%5Cleft%20%5B%20M_i%28w%29%3C0%20%5Cright%20%5D%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5Cleqslant%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5Ctilde%7BQ%7D%28w%2CX%5El%29%3D%5Csum_%7Bi%3D1%7D%5E%7Bl%7D%5Cmathfrak%7BL%7D%28M_i%28w%29%29%5Crightarrow%20%5Cmin_w)

![картинка](https://github.com/Elzara20/university/blob/master/EXAM/loss_function.jpg)

**Вероятностная модель данных**
Множество ![](https://latex.codecogs.com/gif.latex?X\times&space;Y) является вероятностным пространством, и вместо модели разделяющей поверхности ![](https://latex.codecogs.com/gif.latex?f(x,w)) задана параметрическая модель совместной плотности распределения объектов и классов  ![](https://latex.codecogs.com/gif.latex?p(x,y|w)). Для настройки вектора параметров ![](https://latex.codecogs.com/gif.latex?w) по обучающей выборке ![](https://latex.codecogs.com/gif.latex?X^l), которая состаит из независимых наблюдений, применим принцип максимума правдоподобия.

![](https://latex.codecogs.com/gif.latex?p%28X%5El%7Cw%29%3D%5Cprod_%7Bi%3D1%7D%5E%7Bl%7Dp%28x_i%2Cy_i%7Cw%29%5Crightarrow%20%5Cmax_w)


удобнее прологарифмировать:

![](https://latex.codecogs.com/gif.latex?%5Cln%28p%28X%5El%7Cw%29%29%3D%5Cprod_%7Bi%3D1%7D%5E%7Bl%7D%5Cln%28p%28x_i%2Cy_i%7Cw%29%29%5Crightarrow%20%5Cmax_w)


следующие 2 задачи будут эквивалентны, если представить:

![](https://latex.codecogs.com/gif.latex?-%5Cln%28p%28X%5El%7Cw%29%29%3D%5Cmathfrak%7BL%7D%28y_if%28x_i%2Cw%29%29)


Зная модель плотности ![](https://latex.codecogs.com/gif.latex?p(x,y|w)), можно выписать вид разделяющей поверхности ![](https://latex.codecogs.com/gif.latex?f) и функцию ![](https://latex.codecogs.com/gif.latex?\mathfrak{L}). С другой стороны, задавая вид разделяющей поверхности и функцию потерь ![](https://latex.codecogs.com/gif.latex?\mathfrak{L}), казалось бы, из чисто эвристических соображений, мы тем самым неявно принимаем некоторую вероятностную модель данных.

**Линейная модель классификации**
![](https://latex.codecogs.com/gif.latex?X) - множество объектов
![](https://latex.codecogs.com/gif.latex?Y%3D%5Cleft%5C%7B-1%2C1%5Cright%5C%7D) - ответы
![](https://latex.codecogs.com/gif.latex?x%3D%28x%5E1%2C%5Ccdots%20%2Cx%5En%29%5Cin%20%5Cmathbb%7BR%7D%5En%2C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20x%5Ej%3Df_j%28x%29) - признаковое описание объекта ![](https://latex.codecogs.com/gif.latex?x)
Если дискриминантная функция определяется как скалярное произведение вектора ![](https://latex.codecogs.com/gif.latex?x) и вектора параметров ![](https://latex.codecogs.com/gif.latex?w\in\mathbb{R}^n), то получается линейный классификатор:

![](https://latex.codecogs.com/gif.latex?a%28x%2Cw%29%3D%5Ctextrm%7Bsign%7D%28%5Cleft%20%5Clangle%20w%2Cx%20%5Cright%20%5Crangle%20-%20w_0%29%3D%5Ctextrm%7Bsign%7D%28%5Csum_%7Bj%3D1%7D%5E%7Bn%7Dw_jf_j%28x%29-w_0%29)

![](https://latex.codecogs.com/gif.latex?%5Cleft%20%5Clangle%20w%2Cx%20%5Cright%20%5Crangle%20%3D0) -  определяет гиперплоскость, разделяющую классы в пространстве. 
Параметр ![](https://latex.codecogs.com/gif.latex?w_0) иногда опускают. Иногда полагают, что среди признаков есть константа, ![](https://latex.codecogs.com/gif.latex?f_j(x)\equiv&space;-1), и тогда роль свободного коэффициента ![](https://latex.codecogs.com/gif.latex?w_0) играет параметр ![](https://latex.codecogs.com/gif.latex?w_j).
++биологический нейрон и функции активации

## 9. Метод стохастического градиента. Эвристики для улучшения градиентных методов.
> Градиент — это в основном наклон функции; степень изменения параметра вместе с величиной изменения другого параметра


Дано: ![](https://latex.codecogs.com/gif.latex?X%5El%3D%5Cleft%20%5C%7B%20%28x_i%2Cy_i%29%20%5Cright%20%5C%7D_%7Bi%3D1%7D%5E%7Bl%7D%2C%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20x_i%20%5Cin%20%5Cmathbb%7BR%7D%5En%2C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20y_i%20%5Cin%20%5Cleft%20%5C%7B%20-1%2C1%20%5Cright%20%5C%7D)
Нужно: найти вектор весов ![](https://latex.codecogs.com/gif.latex?w%20%5Cin%20%5Cmathbb%7BR%7D%5En), при котором достигается минимум аппроксимированного эмпирического риска:

![](https://latex.codecogs.com/gif.latex?Q%28w%2CX%5El%29%3D%5Csum_%7Bi%3D1%7D%5E%7Bl%7D%5Cmathfrak%7BL%7D%28%5Cleft%20%5Clangle%20w%2Cx_i%20%5Cright%20%5Crangle%20y_i%29%5Crightarrow%20%5Cmin_w)


Применим для минимизации метод градиентного спуска. Выбирается начальное приближение для вектора весов w, затем запускается итерационный процесс, на каждом шаге которого вектор w изменяется в направлении наиболее быстрого убывания функционала Q. Это направление противоположно вектору градиента ![](https://latex.codecogs.com/gif.latex?Q%5E%7B%27%7D%28w%29%3D%28%5Cfrac%7B%5Cpartial%20Q%28w%29%7D%7B%5Cpartial%20w_j%7D%29_%7Bj%3D1%7D%5E%7Bn%7D):

![](https://latex.codecogs.com/gif.latex?w%3Dw-%5Ceta%20Q%5E%7B%27%7D%28w%29)

![](https://latex.codecogs.com/gif.latex?\eta>0) - величина шага в направлении атиградиента или темп обучения. Предполагаем, что функция потерь дифференцируема:

![](https://latex.codecogs.com/gif.latex?w%3Dw-%5Ceta%20%5Csum_%7Bi%3D1%7D%5E%7Bl%7D%5Cmathfrak%7BL%7D%5E%7B%27%7D%28%5Cleft%20%5Clangle%20w%2Cx_i%20%5Cright%20%5Crangle%20y_i%29x_iy_i)

Улучшим сходимость итерационного процесса, выбирая прецеденты по одному и сразу обновляя веса:

![](https://latex.codecogs.com/gif.latex?w%3Dw-%5Ceta%20%5Cmathfrak%7BL%7D%5E%7B%27%7D%28%5Cleft%20%5Clangle%20w%2Cx_i%20%5Cright%20%5Crangle%20y_i%29x_iy_i)

В методе стохастического градиента (stochastic gradient, SG) прецеденты перебираются в случайном порядке. Если же объекты предъявлять в некотором фиксированном порядке, процесс может зациклиться или разойтись.
 
***Весы***: инициализируются различными спосабами. Примеры:
![](https://latex.codecogs.com/gif.latex?w_j%3D0%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%7C%7C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20w_j%3Drand%28-%5Cfrac%7B1%7D%7B2n%7D%2C%5Cfrac%7B1%7D%7B2n%7D%29%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%7C%7C%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20w_j%3D%5Cfrac%7B%5Cleft%20%5Clangle%20y%2Cf_j%20%5Cright%20%5Crangle%7D%7B%5Cleft%20%5Clangle%20f_j%2Cf_j%20%5Cright%20%5Crangle%7D)

Оценки являются точными в одном нереалистичном частном случае — когда функция потерь квадратична и признаки статистически независимы.
***Критерий останова***:когда градиентный метод подходит к окрестности минимума, оценка скользящего среднего стабилизируется и приближается к точному значению функционала.
***параметр сглаживания*** ![](https://latex.codecogs.com/gif.latex?\lambda): можно положить равным ![](https://latex.codecogs.com/gif.latex?\frac{1}{l})

АЛГОРИТМ:
Дано: ![](https://latex.codecogs.com/gif.latex?X^l,\eta&space;,\lambda)
Выход: веса ![](https://latex.codecogs.com/gif.latex?w_i)
1. инициализировать веса ![](https://latex.codecogs.com/gif.latex?w_i)
2. инициализировать текущую оценку функционала: ![](https://latex.codecogs.com/gif.latex?Q%3D%5Csum_%7Bi%3D1%7D%5E%7Bl%7D%5Cmathfrak%7BL%7D%28%5Cleft%20%5Clangle%20w%2Cx_i%20%5Cright%20%5Crangle%20y_i%29)
3. while значение Q не стабилизируется и/или веса w не перестанут изменяться

    3.1 случайным образом выбрать ![](https://latex.codecogs.com/gif.latex?x_i) из ![](https://latex.codecogs.com/gif.latex?X)
    
    3.2  вычислить выходное значение алгоритма ![](https://latex.codecogs.com/gif.latex?a(x_i,w))  и ошибку ![](https://latex.codecogs.com/gif.latex?%5Cvarepsilon_i%3D%5Cmathfrak%7BL%7D%28%5Cleft%20%5Clangle%20w%2Cx_i%20%5Cright%20%5Crangle%20y_i%29)
    
    3.3 сделать шаг градиентного спуска: ![](https://latex.codecogs.com/gif.latex?w%3Dw-%5Ceta%20%5Cmathfrak%7BL%7D%5E%7B%27%7D%28%5Cleft%20%5Clangle%20w%2Cx_i%20%5Cright%20%5Crangle%20y_i%29x_iy_i)
    
    3.4 найти значение Q ![](https://latex.codecogs.com/gif.latex?Q%3D%281-%5Clambda%20%29Q&plus;%5Clambda%20%5Cvarepsilon_i)
    
    
+легко реализуется и обобщается
+подходит для динамического обучения (обучающие объекты поступают потоком и каждый раз обновляется вектор)
+подходит для избыточно больших выборках
-медленно сходится к минимуму
-при большой размерности пространства или малой длине выборки возможно переобучение
-возможность наличия горизонтально асимптоты (Чем больше значение скалярного произведения, тем ближе значение производной L′ к нулю, тем меньше приращение весов ---> некоторые веса будут статичными) 

Улучшения:
- нормализация данных
большие значения нормы векторв объектов ![](https://latex.codecogs.com/gif.latex?%5Cleft%20%5C%7C%20x_i%20%5Cright%20%5C%7C) + функция потерь имеет горизонтальные асимптоты ---> итерационный процесс парализован. Решение (нормализация):
![](https://latex.codecogs.com/gif.latex?x%5Ei%3D%5Cfrac%7Bx%5Ei-x%5Ei_%7B%5Cmin%7D%7D%7Bx%5Ei_%7Bmax%7D-x%5Ei_%7B%5Cmin%7D%7D%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%7C%7C%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20%5C%3B%20x%5Ei%3D%5Cfrac%7Bx%5Ei-x%5Ei_%7Bmean%7D%7D%7Bx%5Ei_%7BmeanSquared%7D%7D)
- gорядок предъявления объектов
Стандартная рекомендация - брать в случайном порядке

    1. Брать объекты из разных классов
    Наибольшее смещение весов ожидается для того объекта, который наименее похож на объекты, предъявленные до него. Называется перетасовкой объектов.
    2. Предъявлять те объекты, на которых была допущена ошибка. Для этого вероятность появления каждого объекта устанавливается пропорционально величине ошибки на данном объекте. Эту эвристику рекомендуется применять только в тех случаях, когда исходные данные не содержат выбросов.
    3. Сравнение величины ошибки с порогом. Если ошибка меньше погора - вектор весов не модифицируется
- квадратичная реализация (также наз. сокращением весов)
Добавляется штрафное слагаемое ![](https://latex.codecogs.com/gif.latex?\tau) 
- выбор величины шага (уменьшение шага с числом итераций ![](https://latex.codecogs.com/gif.latex?\eta) и выбор адаптивного шага)
- выбивание из локольных минимумов (при каждой стабилизации функционалов производить случайные модификации вектора весов, наз. встряхивание коэффициентов)
- ранний останов

## 10. Адаптивный линейный элемент. Персептрон Розенблатта. Теорема Новикова.
[page 8](http://www.machinelearning.ru/wiki/images/6/68/voron-ML-Lin.pdf)
## 11. Логистическая регрессия.
[page 13](http://www.machinelearning.ru/wiki/images/6/68/voron-ML-Lin.pdf)

## 12. Метод опорных векторов. Линейно разделимая выборка.
![](https://latex.codecogs.com/gif.latex?M_i%28w%2Cw_0%29%3Dy_i%28%5Cleft%20%5Clangle%20w%2Cx_i%20%5Cright%20%5Crangle%20-%20w_0%29)

М-отступ
[67](http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf)
Если М>1, то объект xi классифицируется правильно, и находится на некотором удалении от разделяющей полосы.
## 13. Метод опорных векторов для линейно неразделимой выборки
Весь метод - эвристика

[20page, Воронцов](http://www.machinelearning.ru/wiki/images/6/68/voron-ML-Lin.pdf)

Метод эквивалентен минимизации Q (Воронцов) и к [нахождению седловой точки Лагранжа](http://www.machinelearning.ru/wiki/index.php?title=SVM_%D0%B4%D0%BB%D1%8F_%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%BE_%D0%BD%D0%B5%D1%80%D0%B0%D0%B7%D0%B4%D0%B5%D0%BB%D0%B8%D0%BC%D0%BE%D0%B9_%D0%B2%D1%8B%D0%B1%D0%BE%D1%80%D0%BA%D0%B8_%28%D0%BF%D1%80%D0%B8%D0%BC%D0%B5%D1%80%29) 

[brief about two sample:3-5 pages](http://www.machinelearning.ru/wiki/images/archive/a/a0/20150316172222%21Voron-ML-Lin-SVM.pdf)

## 14. Вероятностная постановка задачи обучения. Принцип максимума правдоподобия

Пусть ![](https://latex.codecogs.com/gif.latex?X) — множество объектов, ![](https://latex.codecogs.com/gif.latex?Y) — конечное множество имён классов, множество ![](https://latex.codecogs.com/gif.latex?X\times&space;Y) является вероятностным пространством с плотностью распределения ![](https://latex.codecogs.com/gif.latex?p(x,y)=P(y)p(x|y)). Вероятности появления объектов каждого из классов ![](https://latex.codecogs.com/gif.latex?P_y=P(y)) называются априорными вероятностями классов. Плотности распределения ![](https://latex.codecogs.com/gif.latex?p_y(x)=p(x|y)) называются функциями правдоподобия классов. Далее разделение на 2 класса. [page 18](http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf)

>***Априорная или безусловная вероятность*** представляет собой степень уверенности в том, что данное событие произошло, в отсутствие любой другой информации, связанной с этим событием. Пример: в автопарке 12 машин и 5 мотоциклов, найдите вероятность того, что первому покупателю понравится автомобиль.

***Апостериорной***  ![](https://latex.codecogs.com/gif.latex?P(y|x))называют условную вероятность значения, принимаемого случайной переменной, которое назначается после принятия во внимание некоторой новой, связанной с ней информации, и вычисляется с помощью теоремы Байеса, если известны  ![](https://latex.codecogs.com/gif.latex?p_y(x)) и ![](https://latex.codecogs.com/gif.latex?P_y). 

![](https://latex.codecogs.com/gif.latex?P(y|x)=\frac{p(x,y)}{p(x)}=\frac{p_y(x)P_y}{\sum_{s\in&space;Y}^{}p_s(x)P_s})

С помощью апостериорной вероятности можно определить величину ожидаемых потерь:

![](https://latex.codecogs.com/gif.latex?R(x)=\sum_{y\in&space;Y}^{}\lambda_yP(y|x))

Пример: если перед нами съедобный, круглый, красный предмет, то мы скорей всего определим, что это яблоко. 

*Принцип максимума правдоподобия*: так как функция правдоподобия по Байесу равна  ![](https://latex.codecogs.com/gif.latex?p(x,y)=P(y)p(x|y)), то весь принцип сводится к максимизации апостериорной вероятности:

![](https://latex.codecogs.com/gif.latex?a(x)=\arg\max_{y\in&space;Y}\lambda_yP(y|x))

Если классы равнозначны ![](https://latex.codecogs.com/gif.latex?\lambda_y\equiv1), то байесовское правило называется также принципом максимума апостериорной вероятности. Если классы ещё и равновероятны ![](https://latex.codecogs.com/gif.latex?P_y\equiv\frac{1}{|Y|}), то объект x просто относится к классу y с наибольшим значением плотности распределения ![](https://latex.codecogs.com/gif.latex?p_y(x)) в точке ![](https://latex.codecogs.com/gif.latex?x).
